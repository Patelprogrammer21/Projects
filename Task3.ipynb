{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPd9tex3ozf5eumXemg2vOX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2kZdmgDgN_H","executionInfo":{"status":"ok","timestamp":1726032002499,"user_tz":-330,"elapsed":23402,"user":{"displayName":"Abhishek Kumar Patel (xWF)","userId":"13819027073896267028"}},"outputId":"461b4003-4f47-4b5d-80ab-85a2c59d55dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Getting top 50 companies\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","# Define the User-Agent string\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Mobile Safari/537.36'\n","}\n","\n","# Make a GET request to a URL with the custom User-Agent\n","url = 'https://finance.yahoo.com/quote/%5ENSEI/components/'\n","response = requests.get(url, headers=headers)\n","\n","\n","table_data = []\n","col_name = []\n","count=0\n","soup = BeautifulSoup(response.content, 'html.parser')\n","for i in soup.find_all(\"table\"):\n","    rows = i.find_all('tr')  # Find all rows in the table\n","    for row in rows:\n","        cols = row.find_all('td')  # Find all columns (td elements)\n","        cols = [col.text.strip() for col in cols]  # Extract text and remove extra spaces\n","        table_data.append(cols)\n","\n","table_data = table_data[1:]\n","items = [item[0] for item in table_data]"],"metadata":{"id":"Oh4PQF0RgaEJ","executionInfo":{"status":"ok","timestamp":1726032004106,"user_tz":-330,"elapsed":1611,"user":{"displayName":"Abhishek Kumar Patel (xWF)","userId":"13819027073896267028"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Getting 10 years open and closed price for each companies\n","list_df = []\n","file_names = []  # Names for CSV files inside the zip\n","for item in items:\n","  url = f'https://finance.yahoo.com/quote/{item}/history/?frequency=1d&period1=1388534400&period2=1725779612'\n","  response = requests.get(url, headers=headers)\n","\n","  table_data = []\n","  col_name = []\n","\n","  soup = BeautifulSoup(response.content, 'html.parser')\n","  for i in soup.find_all(\"table\"):\n","      rows = i.find_all('tr')  # Find all rows in the table\n","      for row in rows:\n","          cols = row.find_all('th')  # Find all columns (th elements)\n","          cols = [col.text.strip() for col in cols]  # Extract text and remove extra spaces\n","          col_name.append(cols)\n","          cols = row.find_all('td')  # Find all columns (td elements)\n","          cols = [col.text.strip() for col in cols]  # Extract text and remove extra spaces\n","          table_data.append(cols)\n","\n","  col_name = col_name[0]\n","  col_name = [col.split()[0] for col in col_name]\n","\n","  df = pd.DataFrame(data=table_data, columns=col_name)\n","  df = df.dropna().reset_index(drop = True)\n","  list_df.append(df)\n","\n","  item = item.split('.')[0]\n","  file_names.append(item)\n","  # df.to_csv(f'/content/drive/My Drive/AbhiData/{item}.csv', index=False)\n","  # print(table_data)"],"metadata":{"id":"gGruCQ_1gmgQ","executionInfo":{"status":"ok","timestamp":1726032110060,"user_tz":-330,"elapsed":105959,"user":{"displayName":"Abhishek Kumar Patel (xWF)","userId":"13819027073896267028"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Saving all the csv files into a zip file\n","import io\n","import zipfile\n","\n","# Create a ZIP file in-memory\n","zip_buffer = io.BytesIO()\n","\n","with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:\n","    for df, name in zip(list_df, file_names):\n","        # Write each dataframe to a CSV format in-memory\n","        csv_buffer = io.StringIO()\n","        df.to_csv(csv_buffer, index=False)\n","\n","        # Add the CSV data to the ZIP archive\n","        zf.writestr(name, csv_buffer.getvalue())\n","\n","# Save the ZIP to a file\n","with open('/content/drive/My Drive/AbhiData/TopFiftyCompanies.zip', 'wb') as f:\n","    f.write(zip_buffer.getvalue())\n","\n","print(\"ZIP file with dataframes created successfully.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5RUGa-mgqPq","executionInfo":{"status":"ok","timestamp":1726032110672,"user_tz":-330,"elapsed":620,"user":{"displayName":"Abhishek Kumar Patel (xWF)","userId":"13819027073896267028"}},"outputId":"76444077-46e1-442f-a4bf-220ed721b854"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ZIP file with dataframes created successfully.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GgpGPSIrhcEN"},"execution_count":null,"outputs":[]}]}